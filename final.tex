\documentclass[report]{jlreq}

\usepackage{listings}
\author{2013553 中野将生}
\date{\today}
\title{S8 最終レポート}

\lstset {
  language = caml,
  breaklines = true,
  tabsize = 2,
  numberstyle = \tiny,
  basicstyle = \ttfamily\small,
  numbers = left,
  frame = TBrl
}

\begin{document}
  \maketitle
  \chapter{成果物の概要}
    本実験で実装した処理系は\texttt{./code/bin/main.ml}と\texttt{./compiler/main.ml}の2種類である。
    前者の処理系は課題6-2までの機能を実装した木構造に対するインタプリタ、
    CAM、ZAMへのコンパイルと実行が可能である。第一引数に\texttt{tree}、\texttt{cam}、\texttt{zam}を指定し、
    第２引数にファイルを指定する事で実行できる。
    後者の処理系はパターンマッチ、高階型を含む多相型推論と、簡単なサブセット言語のコンパイル機能がある。
    簡単のため以降前者をコンパイラ1、後者をコンパイラ2と呼ぶ。

    コンパイラ1は\texttt{code}ディレクトリで\texttt{dune build}を行うと\texttt{code/\_build/default/bin/main.exe}
    に実行可能ファイルが生成される。コンパイラ2は\texttt{./compiler}ディレクトリで\texttt{make}を実行すれば
    単体テストが実行され\texttt{compiler}という名前でコンパイラがビルドされる。
  \chapter{実行例}
    \subsection{マッカーシーの91関数}
      図\ref{maccarthy-91-ml}にソースコードを、図\ref{maccarthy-91-result}に実行結果を示す。
      かなり軽い処理で実行時間の計測はあまり意味が無かった。
      \lstinputlisting[caption = コンパイラ1によるMcCarthy91の実行結果, label=maccarthy-91-result]{./figures/maccarchy91.sh}
      \lstinputlisting[caption = maccarthy91.ml, label=maccarthy-91-ml]{./code/example/maccarthy91.ml}
    \subsection{フィボナッチ数列}
      図\ref{fib-exec}はソースコード\ref{code-fib-ml}をコンパイラ1を用いて実行した際の結果である。
      \texttt{tree}が最も遅いのは自然な結果だが、\texttt{ZAM}も\texttt{tree}と殆ど同じ速度となっている。
      命令セットｔが複雑なため、フィボナッチ数列のような単純なプログラムではあまり速度が出ない可能性、
      ランタイムが効率の良い実装になっていない可能性が考えられる。
      特にZAMでは\texttt{Grab}命令を追加した事で複数引数を効率よく扱えるようにはなっているが、
      フィボナッチ数列だと引数は一つしか取らないためかえってオーバーヘッドが生じている可能性がある。
      \lstinputlisting[caption = fib.ml, label = code-fib-ml]{./code/example/fib.ml}
      \lstinputlisting[caption = コンパイラ1によるfibの実行結果, label = fib-exec, language=bash]{./figures/bench.sh}

      図\ref{compiled-fib-result}はソースコード\ref{code-fib-ml-stmt}をコンパイラ2でコンパイルした後
      実行した際の結果である。
      コンパイル時間と実行時間を別々に計測している。
      コンパイル時間を含めてもインタプリタ実装に比べ高速な実行が出来ているが、
      CAMの実行時間はバイナリの$1.8$倍に過ぎないのであまり効率の良いコードを生成しているとは言えない。
      \lstinputlisting[caption = コンパイラ2によるfibの実行結果, label=compiled-fib-result]{./figures/bin_bench.sh}
      \lstinputlisting[caption = fib\_stmt.ml, label=code-fib-ml-stmt]{./compiler/example/fib.ml}

      参考までに\texttt{ocaml}と\texttt{ocamlopt}によって生成されたバイナリの実行結果を示す。
      ソースコードはコンパイラ2のものと同一である。
      \lstinputlisting[caption = OCamlによるfibの実行結果]{./figures/fib_ocaml.sh}
    \subsection{Ack関数とTarai関数}
    　また上記の関数の他に図\ref{ack}に示すAck関数と図\ref{tarai}に示すたらい回し関数でも試験した。
      実行結果を表\ref{compare-tbl}に示す。
      バイナリコンパイラはインタプリタと比較して明らかに高速である。
      Ack関数でインタプリタが非常に低速になっている反面コンパイラはOCaml処理系と概ね同等の速度を維持しているのが特徴的である。
      これはバイナリコンパイラは非効率な部分はあるもの、\texttt{x86\_64}のアセンブリに変換する以上
      関数のコードを静的に配置せざるをえず、動的に再帰コードを生成するインタプリタに対してパフォーマンス上の優位があるのではないかと考えられる。
      CAMのみN/Aの項目があるが、これはVMのバグで途中で計算に失敗しているためである。
      デバッグの時間が無く直せなかった。
      \lstinputlisting[caption = Ack関数,   label=ack]{./code/example/ack.ml}
      \lstinputlisting[caption = Tarai関数, label=tarai]{./code/example/tarai.ml}
      \begin{table}[t]
        \centering
        \label{compare-tbl}
        \caption{実行速度の比較表}
        \begin{tabular}{l|lll}
        implementation & fib 35             & tarai 12 6 0         & ack 3 11            \\ \hline
        ocamlopt       & $64.86           $ & $ 30.01            $ & $ 69.74            $ \\
        ocaml          & $387.18          $ & $ 161.78           $ & $ 373.41           $ \\
        compiler2      & $932.89          $ & $ 697.62           $ & $ 873.88           $ \\
        compiler1 tree & $2.71 \cdot 10^3 $ & $ 2.11 \cdot 10^3  $ & $ 12.47 \cdot 10^3 $ \\
        compiler1 cam  & $1.83 \cdot 10^3 $ & $ \mathrm{N/A}     $ & $ \mathrm{N/A}     $ \\
        compiler1 zam  & $2.70 \cdot 10^3 $ & $ 1937.38          $ & $ 16.03 \cdot 10^3 $
        \end{tabular}
      \end{table}
    \subsection{型推論器の検証}
      型推論器の動作を示す。
      \subsubsection{たらい回し関数に対する単相型付け}
        図\ref{tarai}のたらい回し関数に対して型推論を行った結果が図\ref{tarai-type-dump}である。
        これは変数がアルファ変換されておりかなり読みづらいので手で整形したのが図\ref{tarai-type-pretty}である。
        短絡or演算子がifに、二項演算子を関数適用に変換する事でコードを一般化している。
        let宣言はinを使って纏めて一つの式として扱う事で型推論器のコードを減らしている。末尾のNeverはソースコード末尾を示すマーカーである。
        再帰関数ではあるが正しく$\mathrm{int} \rightarrow \mathrm{int} \rightarrow \mathrm{int} \rightarrow \mathrm{int}$と型が付いている
        \lstinputlisting[caption = tarai.mlに対する\texttt{compiler typing}の出力, label=tarai-type-dump]{./figures/tarai_typing_dump.txt}
        \lstinputlisting[caption = tarai.mlの型, label=tarai-type-pretty]{./figures/tarai_typing_pretty.txt}

      \subsubsection{多相型推論}
        単相型システムでは
        図\ref{id-typing}のような式はエラーとなるが、
        多相型システムの元では正しく型が付く。また図\ref{map-typing}のような高階型を取る多相関数にも正しく型をつける事が可能である。
        \lstinputlisting[caption = id, label=id-typing]{./figures/id_typing.txt}
        \lstinputlisting[caption = List.mapへの型つけ, label=map-typing]{./figures/map_typing.txt}
        図\ref{eq-poly}では引数\texttt{x}と引数\texttt{y}が同じ多相型になっているが、
        図\ref{eq-mono}では\texttt{id}を多相型に推論してもunsoundは起こらないが推論アルゴリズムの関係上このような型が付く。
        図\ref{eq-poly2}のようにfの外でfを利用した場合は多相な型が付く。
        \lstinputlisting[caption = 多相型へのunify, label=eq-poly]{./figures/eq_poly.txt}
        \lstinputlisting[caption = 多相型へのunify, label=eq-mono]{./figures/eq_mono.txt}
        \lstinputlisting[caption = 多相型へのunify, label=eq-poly2]{./figures/eq_poly2.txt}
        図\ref{cannot_unify1}のように$'0 -> '0 -> \mathrm{bool}$な関数に$\mathrm{int}, \mathrm{bool}$を適用しようとすると単一化に失敗してエラーが発生する。
        \lstinputlisting[caption = 単一化の失敗, label=cannot_unify1]{./figures/cannot_unify.txt}
        ただしこの型システムにはunsoundが存在し、多相な型を持ち、かつその中の値にアクセスできるようなデータがあった場合に$\mathrm{int}$に$\mathrm{bool}$を入れるような事が出来てしまう。
        図\ref{unsound}が実際のコードである。OCamlの処理系では値制限と呼ばれる方法によって型エラーとして検出可能だが、
        コンパイラ2には値制限は実装されていないので型が付いてしまう。
        \lstinputlisting[caption = Unsound, label=unsound]{./figures/unsound.txt}
        また多相性は\texttt{let}によって導入されるため、図\ref{mono-id}のように\texttt{fun}だけで同様の事を行っても多相な型は付かずエラーとなる。
        \lstinputlisting[caption = Mono id, label=mono-id]{./figures/mono_id.txt}
      \subsubsection{Zコンビネータ}
        型をつける事が難しいものの型エラーが発生せず実行できるような式も存在する。図\ref{zcombinator}のような不動点コンビネータがその一例である。
        コンパイラ2は型が循環している事を検知してコンパイルエラーとするが、型検査を行わないコンパイラ1だと正常に実行可能である。
        なおOCamlでも\texttt{-rectypes}オプションにより実行は可能である。
        \lstinputlisting[caption = Typing Z combinator, label=zcombinator]{./figures/z.txt}

  \chapter{実装したコンパイラの解説及び言語処理系の考察}
    コンパイラ2は以下のような構成となっている。
    \begin{itemize}
      \item \texttt{lex.ml}
      \item \texttt{parser.ml}
      \item \texttt{ast.ml}
      \item \texttt{alpha.ml}
      \item \texttt{typing.ml}
      \item \texttt{closure.ml}
      \item \texttt{codegen.ml}
      \item \texttt{emit.ml}
    \end{itemize}
    \section{構文解析}
      \texttt{lex.ml}と\texttt{parser.ml}が担当している。
      PEGのようなパーサコンビネータを用いて一つの構文解析器のみで抽象構文木を構築することも可能であるが、
      パターンマッチを用いて構文解析器を記述したいモチベーションがあったことと、
      なるべく階層化してテストを容易にするために分割した。

      lexはトークンを認識すると同時に改行を把握してトークンとソースコード上での位置情報を結びつける。
      この位置情報は純粋なコンパイラの実装としては余分だが、
      大規模なファイルをコンパイルする際には位置情報が無いとデバッグが困難になる。

      LR(1)パーサジェネレータは遷移表とアクション表を用いてボトムアップに構文解析器を行っていくため確かに
      効率は高いが、反面パーサジェネレータに習熟しなければ文法のconflictの解消が難しい。
      また適切なエラーメッセージを出すのがやや困難である。
      Menhirのマニュアルにはエラーメッセージを設定する方法が記述されているが、
      再帰下降構文解析器の方がエラーメッセージを出し分けるのは容易である。
      またOCamlは右側に向かってぶら下がっていくような規則が多く、
      文法のconflictがLRだと起きやすい。
      また再帰下降構文解析器では左再帰が不可能なので左結合する演算子のパースは構文解析してから組み替える工夫が必要である。
      このためにカッコ情報のような本質的でない情報がASTに残る欠点がある。
    \section{構文木変換}
      \texttt{ast.ml}が担当している。　
      パーサが左再帰の解消ために生成するカッコなどの余分な情報の削除、
      演算子の関数への変換を行う。
    \section{アルファ変換}
      \texttt{alpha.ml}が担当。
      ソースコード中のシンボルを一意なIDへ変換する。
      MLでは変数のシャドウイングが許されるため同じ名前の変数が同じ実体意味するとは限らないためである。
      ただしアルファ変換をするとその後のテストがかなり面倒になる。
      OCamlの等価比較演算子は任意の型に対して作用するが、
      その動作をオーバーライドする事が出来ないため、
      テストを書く際に自動生成されたIDを予測して書くか、
      パターンマッチでIDを抜き出し手で条件を書き事になる。
      テストコードの記述をサボると後のパスで厄介なバグとして現れるのでかなり難しかった。
    \section{型推論}
      Hindley-Milner型システム\cite{hindley1969the,milner1978a}の型推論アルゴリズムとしてはAlgorithm W\cite{damas1982principal}が有名であるが、
      本コンパイラでは実装の簡便さのためにレベルを持ちいた型推論システム\cite{remy1992extension}を用いた。

      基本的には未知の型を一旦型変数で置き、unify関数によってそれらを単一化していくのだが、
      不定のままだった型変数を多相型に変換するgeneralizeと、多相型を未知の方変数へ再び変換するinstantiateが登場する。
      letの定義に入る際にアロケートされる型変数のレベルを一つ上げ、letの定義から抜ける際にletに入る前よりレベルが高い型変数を全て多相型に変換する。
      そして多相型を含む型をunifyする際は多相型を全て型変数に変換してから単一化を行う。
      未知の型と未知の型をunifyする際はレベルが低い方に合わせる。

      論文\cite{remy1992extension}ではグラフに対して型推論アルゴリズムを実装していたが、
      破壊的代入を用いる事は本実験の趣旨から外れるものの、
      本コンパイラでは古典的な型環境を参照しつつ代入を使ってunifyする事で実装した。

    \section{クロージャ変換}
      スコープが階層をなすMLと違い、x86\_64アセンブリでは\texttt{.bss}、\texttt{.data}に置かれた変数以外はスタックかレジスタで渡されない限り見えない。
      そこで外側のスコープの変数を暗黙にキャプチャしているクロージャについて全て陽に関数適用として変数を与えるように変換する必要がある。
      この実装は単にクロージャ内部で使用されている変数から引数で宣言されたもの、
      クロージャ内部で宣言されたものを引けば自由変数が手に入るのでそれを陽に渡すようにクロージャを書き換えるだけである。

      ただしここで2点注意することとして、関数を参照している場合や、トップレベルの\texttt{.data}や\texttt{.bss}に配置されるクロージャは
      陽に渡すべき自由変数と考えなくて良いということ、クロージャが再帰する場合があるので暗黙にキャプチャしていた変数を陽な関数適用とする場合は
      新しい束縛を作れない事がある。
      前者は実装せずとも引数の数が増えるだけなので最低限pervasiveな関数を除外すればそれほど困らないが、
      可能な限り関数をトップレベルに移してからトップレベルの関数をキャプチャ対象から除外する方が効率的である。

      後者の操作は関数型的な操作ではないが、処理系しかこのようなコードを生成することは無いので問題ない。
    \section{コード生成}
      本コンパイラでは処理系が生成する一部の処理を除き全て変数をスタックに確保したメモリに入れ、
      またスタック領域の再利用を行わない事で短時間で実装した。
      本来であれば可能な限りレジスタ上に収め、またスタックの領域も生存区間を解析して再利用すべきではある。
      春休み中に全体のリファクタリングとバックエンドの書き直しを行いたい。

      レジスタ割付について、実際に呼び出し規約等や命令を調べるまでは比較的単純な制約の問題に落とし込めると考えていたが、
      実際の命令は特定のレジスタに限られるものもあり、そう簡単ではない事が分かった。

      OCamlのような多相型システムをx86コードに落とし込む際にには2種類の戦略が考えられる。
      一つは今回採用した値を全て多相型として扱えるように設計し、多相関数をそのまま多相関数としてコンパイルする方法であり、
      もう一つは多相な型対し、使用箇所を追って単相な型に展開する方法である。

      後者の単相化を行う戦略はSMLの処理系であるMLton\cite{weeks2006whole}で採用されている。
      自明な関数呼び出し（両側の型が単相な比較演算子呼び出し）はそのまま単相な実装をに変換すればいいが、
      多相関数を値として渡せる以上単相な型を複数束ねて渡す場面が出てくる。
      この時あり得る全ての関数を渡すとメモリコピーでオーバーヘッドが発生する上レジスタを圧迫し
      最適化の邪魔となるので必要最低限のみ渡すようにしなければならない。
      そのためどの部分でどれだけ単相化された値が必要なのかをグラフを用いて推論する機構が必要となる。
      またこれを行う事で分割コンパイルが困難になる問題もある。
      また多相関数が複数の実装に分岐することになるので他の言語とFFIで連携することが難しくなる。

      多相なままメモリ上で表現する戦略はさらなる推論でより多くの情報を収集する必要はあまりなく、
      単相な値で多相な値を表現するためにメモリ使用量が増加することも無いが、
      一方でバイナリ形式を工夫しなるべくオーバーヘッドを減らす必要がある。

      多相な型をそのまま扱う以上メモリ上のサイズは同じであった方が都合が良い（特に$64 \mathrm{bit}$のレジスタに乗り切ると良い）が、
      ここで愚直に全てポインタで実装してポインタの先で処理を分岐させるとオーバーヘッドが非常に大きくなってしまう。
      \texttt{int + bool}のような演算は発生しない事がMLの型システ厶保証されているので、
      booleanとintegerは統合することが出来る。
      またx86\_64ではポインタは$64 \mathrm{bit}$であるが全てのビットが使用される訳ではない。
      そのため整数のうち$1 \mathrm{bit}$をマーカに使う事で整数と真偽値はポインタではなく直接値として扱える。
      ただしIEEE754は整数のように一部のbitを削ることは出来ないのでポインタの先に格納するしかない。
      タプルやヴァリアントも、クロージャも同様にポインタの先に格納することになるが、
      毎回mallocを呼ぶのはコストがかかる上解放の為にGCを使う必要がある。
      静的型がついているので型チェックは全て省略出来るが、ある程度のオーバーヘッドは発生する。

      この間の折衷案としてモジュール内部で閉じている部分は単相化することで分割コンパイルを可能にしつつなるべく高速化する戦略や、
      小さいタプルだけポインタの先に入れず直接扱う戦略も考えられる。

      $\mathrm{int} \rightarrow \mathrm{int} \rightarrow \mathrm{int}$に$\mathrm{int}$を適用したものと
      $\mathrm{int} \rightarrow \mathrm{int}$は同じ型として扱われるが、
      実際は前者はクロージャとして$\mathrm{int}$を後者よりひとつ多く持つ。
      格納順を逆にすればある程度の高速化が期待できるが、
      関数として宣言したものをクロージャに変換出来る事を考えると、
      MLの関数はCから見ると引数が逆順に定義されているように見えるので相互運用性の確保が難しい。

      IR設計も難しかった。\texttt{if}、\texttt{let}ぐらいの簡単なものでああれば比較的楽だが、
      パターンマッチの実装を考えるとかなり柔軟性のあるIRを設計する必要がある。
      ただしここの柔軟性が上がるとフローを解析し低レベルな最適化パスを入れるのが難しくなりそうな気がした。
      LLVM IRぐらいの抽象度が一番良いのかもしれない。

    \section{出力}
      今回はgccを使ったが将来的には\texttt{as}と\texttt{ld}をそのまま使うようにしたい。
      アセンブリを書くにあたってGNU asのドキュメントと命令の仕様にいきなり当たるしか無くかなり大変だった。
  \chapter{本実験全体の考察及び感想}
    きちんとレイヤに分けて分割した問題を解いていけばバイナリを吐くところまでなんとかたどり着けたのは少し感動した。
    MLコンパイラは昔一度書きかけて途中で投げてしまったが、今ならセルフホストまで頑張れる気がするので実験が終わった後も開発は続けたい。
    \section{関数型プログラミング言語について}
      関数型プログラミング言語が何かは正直良くわかってないのだが、
      処理系を書いていてHM型システ厶はかなり上手く出来ていると感じた。
      テンプレートではなく実行時の値として多相な値を取れたりクロージャを扱える柔軟性がありながら、
      実行時型チェックを実装せずとも破綻なく動くのはかなりいいバランスだと思う。
  \chapter{ソースコード}
    \lstinputlisting[caption = Typing Z combinator]{./codemap.txt}
    \include{./sourcelist.tex}
    \include{./typetestlist.tex}
    \include{./bench_list.tex}
  \bibliographystyle{plain}
  \bibliography{refs}
\end{document}
